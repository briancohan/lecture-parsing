{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from parse import parse, search, findall\n",
    "from lark import Lark\n",
    "from lark.lexer import Token\n",
    "from lark.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-miniature",
   "metadata": {},
   "source": [
    "# Read a Text File\n",
    "\n",
    "In order to parse some text, you need to get it into your program. Sure, you could hard code it in as a variable, but that's not as useful. So we'll start by looking at ways to use native functions to read text.\n",
    "\n",
    "Function | Use\n",
    "---|---\n",
    "`f.read()` | Read the **entire** file in at once\n",
    "`f.readlines()` | Read the **entire** file in, split on each line. (`f.read().split('\\n')`, but preserves `\\n` character)\n",
    "`f.readline()` | Red **one line** in at a time. Good for very long files that may not fit into memory. (preserves `\\n` character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one variable\n",
    "with open('data/couch.txt') as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse one \"line\" at a time, note it keeps the \\n, so tell print not to print another new line character\n",
    "with open('data/couch.txt') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        print(i, line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one line at a time if you're worried about a large file using up too much RAM\n",
    "with open('data/couch.txt') as f:\n",
    "    while (line := f.readline()):\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-desert",
   "metadata": {},
   "source": [
    "Python's `pathlib` module can help make this a little cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read entire file in with pathlib\n",
    "txt = Path('data/couch.txt').read_text()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each line using pathlib\n",
    "lines = Path('data/couch.txt').read_text().split('\\n')\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-press",
   "metadata": {},
   "source": [
    "# Parsing Info From Text File With String Methods\n",
    "https://docs.python.org/3/library/stdtypes.html#string-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out blank lines with the truthiness of the line\n",
    "# This only works because we've stripped the \\n character from each line\n",
    "for line in lines:\n",
    "    if line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get any line that has a `:` and split it into the variable and the value\n",
    "variables = dict()\n",
    "for line in lines:\n",
    "    parts = line.split(':', 1)\n",
    "    if len(parts) > 1:\n",
    "        variables[parts[0].strip()] = parts[1].strip()\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use string methods to only get numeric types\n",
    "for line in lines:\n",
    "    parts = line.split(':', 1)\n",
    "    try:\n",
    "        if parts[1].strip().isnumeric():\n",
    "            print(line)\n",
    "    except IndexError:\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPI version has a `.` which does not work. You could try casting to a float\n",
    "for line in lines:\n",
    "    parts = line.split(':', 1)\n",
    "    try:\n",
    "        float(parts[1])\n",
    "        print(line)\n",
    "    except (IndexError, ValueError):\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-sudan",
   "metadata": {},
   "source": [
    "# Parse using Regular Expressions\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "https://regex101.com/\n",
    "\n",
    "Function | Use\n",
    "---|---\n",
    "`re.search(pattern, text)` | See if `pattern` is **in** `text`, return first\n",
    "`re.match(pattern, text)` | See if `text` **starts** with `pattern`, return first\n",
    "`re.findall(pattern, text)` | Find **all** occurences of `pattern` in `text`, returns **string**\n",
    "`re.finditer(pattern, text)` | Find **all** occurence of `pattern` in `text`, returns **match object**\n",
    "`re.split(pattern, text, max)`| Split `text` on `pattern`\n",
    "\n",
    "Pattern | Meaning\n",
    "---|---\n",
    "`.` | Match **anything** other than a new line `\\n`\n",
    "`^` | Match at **start** of text\n",
    "`$` | Match at **end** of text\n",
    "`*` | Pattern appears **0 or more** Times\n",
    "`+` | Pattern appears **1 or more** Times\n",
    "`?` | Pattern appears **0 or 1** Times\n",
    "`{m}` | Pattern appears **m** number of Times\n",
    "`{m,n}` | Pattern appears **between `m` and `n`** Times\n",
    "`[]` | Define a **set** of characters to match\n",
    "`()` | Define a **group** of characters to match\n",
    "\n",
    "Sequence | Meaning | Sequence | Meaning\n",
    "---|---|---|---\n",
    "`\\d` | Any digit 0-9 | `\\D` | Anything but a digit 0-9\n",
    "`\\s` | Any whitespace `[ \\t\\n\\r\\f\\v]` | `\\S` | Anything but whitespace\n",
    "`\\w` | Any word character `[a-zA-Z0-9]` | `\\W` | Anything but a word character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '\\w+ Discord'\n",
    "text = \"The Python Discord is cool, but the PyRVA Discord is better!\"\n",
    "print(re.match(pattern, text))\n",
    "print(re.search(pattern, text))\n",
    "print(re.findall(pattern, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's up with `search`? It returned a `match object` where you can extract the sub-patterns.\n",
    "# The whole string will always be group 0 while sub groups start at 1.\n",
    "# `match` would have returned a `match object` if there was a match.\n",
    "result = re.search(pattern, text)\n",
    "result.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# () defines a sub-group, in this case, the names of the servers.\n",
    "pattern = '(\\w+) Discord'\n",
    "[r.group(1) for r in re.finditer(pattern, text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a small section of a file.\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a date! We can contrive a patter that will match the dates. Note how the developers were annoying and used a bunch of different formats\n",
    "pattern = '[a-zA-Z]+\\s+\\d+(, \\d+)?\\s+\\d+:\\d+:\\d+'\n",
    "for line in lines:\n",
    "    if match := re.search(pattern, line): # I am the walrus!\n",
    "        print(line)\n",
    "        print(match)\n",
    "        print(match.group(0))\n",
    "        print(match.group(1))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First date! search will return the first match it finds.\n",
    "re.search(pattern, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dates! findall and finditer will find multiple matches.\n",
    "list(re.finditer(pattern, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the date. Use group(0) to extract just the matched part\n",
    "[m.group(0) for m in re.finditer(pattern, txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could make things a *little* eaiser to read by breaking it up, but this really isn't eactly easier to read either.\n",
    "date = '[a-zA-Z]+\\s+\\d+'\n",
    "year = '(, \\d+)?'\n",
    "time = '\\s+\\d+:\\d+:\\d+'\n",
    "pattern = date + year + time\n",
    "list(re.finditer(pattern, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to see how the model progressed over time. We can extract data and look at the simulation time vs wall clock time.\n",
    "# Here is the info we want to parse. The wall clock time is on one line while the total time is on another.\n",
    "# Time Step       1   March  7, 2021  22:29:32\n",
    "# Step Size:    0.102E+00 s, Total Time:       0.10 s\n",
    "\n",
    "pattern = (\n",
    "    'Time Step\\s+(?P<timestep>\\d+)'\n",
    "    '\\s+(?P<date>[a-zA-Z]+\\s+\\d+,\\s+\\d+\\s+\\d+:\\d+:\\d+)'\n",
    "    '\\s+Step Size:\\s+(?P<stepsize>[0-9\\.E+-]+)\\s+s,'\n",
    "    '\\s+Total Time:\\s+(?P<simtime>[0-9\\.]+)'\n",
    ")  # Python will concatenate strings that don't have a comma\n",
    "\n",
    "out = Path('data/couch/couch.out').read_text()\n",
    "df = pd.DataFrame([r.groupdict() for r in re.finditer(pattern, out)])\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_line().encode(x='date', y='simtime:Q')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-webster",
   "metadata": {},
   "source": [
    "# Parse Stuff with Parse\n",
    "https://pypi.org/project/parse/\n",
    "\n",
    ">`parse()` is the opposite of `format()`\n",
    "\n",
    "Function | Use | Regular Expression\n",
    "---|---|---\n",
    "`parse(ptn, txt)` | See if `txt` **starts** with `ptn`, return first | `re.match`\n",
    "`search(ptn, txt)` | See if `ptn` is **in** `txt`, return first | `re.search`\n",
    "`findall(ptn, txt)` | Find **all** occurences of`ptn` in `txt` | `re.findall`\n",
    "\n",
    "\n",
    "There is support for regex, but you can discover that on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the snippet of text again\n",
    "# Time Step       1   March  7, 2021  22:29:32\n",
    "# Step Size:    0.102E+00 s, Total Time:       0.10 s\n",
    "\n",
    "# This pattern is MUUUCH more readable\n",
    "pattern = \"Time Step {:>d} {:^} Step Size: {:>} s, Total Time: {:>d}\"\n",
    "result = search(pattern, out)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get positional arguments\n",
    "result.fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also suppply names to the different parameters\n",
    "pattern = \"Time Step {timestep:>d} {date:^} Step Size: {stepsize:>} s, Total Time: {simtime:>d}\"\n",
    "result = search(pattern, out)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the named variables\n",
    "result.named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load the list of dictionaries into pandas to have a look.\n",
    "pd.DataFrame([r.named for r in findall(pattern, out)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-assurance",
   "metadata": {},
   "source": [
    "# Parse Stuff with Pandas\n",
    "- https://pandas.pydata.org/\n",
    "  - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "  - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse csv files\n",
    "hrr = pd.read_csv('data/couch/couch_hrr.csv', header=1)\n",
    "hrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(hrr).mark_line().encode(x='Time', y='HRR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file formatted in fixed width font\n",
    "pd.read_fwf('data/fwf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read html tables on a web page\n",
    "url = 'http://toscrape.com/'\n",
    "html_tables = pd.read_html(url)\n",
    "html_tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from a JSON api\n",
    "url = 'https://data.virginia.gov/resource/bre9-aqqr.json'\n",
    "pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-kitty",
   "metadata": {},
   "source": [
    "# Parse using Grammar Parser\n",
    "https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form\n",
    "\n",
    "https://github.com/lark-parser/lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets a bit complex, but is a very powerful tool\n",
    "grammar = '''\n",
    "start: record+\n",
    "record: \"&\" NAMELIST (_SEP keyval)* \"/\"\n",
    "keyval: PARAM \"=\" (VALUE | value_list)\n",
    "value_list: VALUE (_SEP VALUE)+\n",
    "\n",
    "NAMELIST: UCASE_LETTER~4\n",
    "PARAM: CHAR+\n",
    "VALUE: SIGNED_NUMBER | QUOTED_STRING | \".FALSE.\" | \".TRUE.\"\n",
    "CHAR: UCASE_LETTER | DIGIT | \"_\"\n",
    "QUOTED_STRING: \"'\" _STRING_INNER \"'\"\n",
    "_SEP: WS | \",\"\n",
    "\n",
    "%import common._STRING_INNER\n",
    "%import common.DIGIT\n",
    "%import common.SIGNED_NUMBER\n",
    "%import common.UCASE_LETTER\n",
    "%import common.NEWLINE\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "'''\n",
    "parser = Lark(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDENT = 4\n",
    "def display(node, indent: int = INDENT):\n",
    "    \"\"\"Nicely display the AST.\"\"\"\n",
    "    _ind = \" \" * indent\n",
    "    if isinstance(node, Token):\n",
    "        print(_ind, node.line, node.column, node.type, node.value)\n",
    "    else:\n",
    "        print(_ind, node.data)\n",
    "        for child in node.children:\n",
    "            display(child, indent + INDENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse an input file\n",
    "tree = parser.parse(Path('data/couch/couch.fds').read_text())\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-ukraine",
   "metadata": {},
   "source": [
    "# The Future of Parsing in Python\n",
    "\n",
    "- [PEP 622 - Structural Pattern Matching](https://www.python.org/dev/peps/pep-0622/)\n",
    "- [PEP 634 - Structural Pattern Matching: Specification](https://www.python.org/dev/peps/pep-0634/)\n",
    "- [PEP 635 - Structural Pattern Matching: Motivation and Rationale](https://www.python.org/dev/peps/pep-0635/)\n",
    "- [PEP 636 - Structural Pattern Matching: Tutorial](https://www.python.org/dev/peps/pep-0636/)\n",
    "- [Python 3.10 Pattern Matching in Action](https://www.youtube.com/watch?v=SYTVSeTgL3s)\n",
    "- [Pattern matching tutorial for Pythonic code](https://mathspp.com/blog/pydonts/pattern-matching-tutorial-for-pythonic-code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-disclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
